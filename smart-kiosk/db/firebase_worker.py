"""
db/firebase_worker.py

Background worker that processes DB payloads enqueued by SessionManager/services.

Features:
- Consumes dict payloads from a queue.Queue (non-blocking enqueuing by producers).
- Retries failed payloads with exponential backoff up to `max_retries`.
- If a payload exhausts retries, writes it to a dead-letter JSONL file for later inspection/replay.
- Pluggable `process_fn(payload)` to integrate your firebase_helpers module.
- Graceful shutdown via stop() and join().

Expected payload shape (examples generated by SessionManager/water_service/charging_service):
    {"op": "session_start", "session": {...}}
    {"op": "coin", "session_id": "...", "value": 5}
    {"op": "dispense_increment", "session_id": "...", "ml": 50}
    {"op": "slot_charging_start", "slot": 1, "session_id": "...", "amps": 1.23}
The worker is intentionally generic to keep it decoupled from DB API details.
"""

from __future__ import annotations
import threading
import time
import json
import logging
import os
from typing import Any, Callable, Dict, Optional
import queue
import traceback

_LOGGER = logging.getLogger("[FIREBASE_WORKER]")


class FirebaseWorker(threading.Thread):
    def __init__(
        self,
        db_queue: "queue.Queue[Dict[str, Any]]",
        process_fn: Optional[Callable[[Dict[str, Any]], bool]] = None,
        max_retries: int = 5,
        retry_base_seconds: float = 1.0,
        dead_letter_path: str = "db_failed.jsonl",
        poll_timeout: float = 1.0,
        name: str = "FirebaseWorker",
    ):
        """
        Args:
            db_queue: queue.Queue() instance where producers put payload dicts.
            process_fn: callable(payload) -> bool. Return True on success, False on transient failure.
                        If None, the worker will attempt to import db.firebase_helpers.process_payload(payload).
            max_retries: how many times to retry a failing payload before dead-lettering.
            retry_base_seconds: base for exponential backoff (sleep = retry_base_seconds * 2**attempt).
            dead_letter_path: file path to append JSON lines for unrecoverable payloads.
            poll_timeout: queue.get timeout in seconds (worker checks stop flag periodically).
        """
        super().__init__(name=name, daemon=True)
        self.db_queue = db_queue
        self.process_fn = process_fn or self._auto_discover_process_fn()
        self.max_retries = int(max_retries)
        self.retry_base_seconds = float(retry_base_seconds)
        self.dead_letter_path = dead_letter_path
        self.poll_timeout = float(poll_timeout)

        self._stop_event = threading.Event()
        # Ensure dead-letter directory exists
        try:
            dl_dir = os.path.dirname(os.path.abspath(self.dead_letter_path))
            if dl_dir and not os.path.exists(dl_dir):
                os.makedirs(dl_dir, exist_ok=True)
        except Exception:
            _LOGGER.exception("Failed to ensure dead-letter directory")

    # -----------------------
    # Auto-discovery fallback
    # -----------------------
    def _auto_discover_process_fn(self) -> Optional[Callable[[Dict[str, Any]], bool]]:
        """
        Try to import a helper process_payload from db.firebase_helpers.
        If not available, return None and the worker will dead-letter payloads (safe fallback).
        """
        try:
            import db.firebase_helpers as fh  # type: ignore
            if hasattr(fh, "process_payload") and callable(getattr(fh, "process_payload")):
                _LOGGER.info("Discovered db.firebase_helpers.process_payload as process_fn")
                return getattr(fh, "process_payload")
            # else, return None so caller must pass a process_fn or worker will log+dead-letter
            _LOGGER.warning("db.firebase_helpers found but no process_payload(payload) function present")
            return None
        except Exception:
            _LOGGER.info("db.firebase_helpers not available; worker will require explicit process_fn or will dead-letter")
            return None

    # -----------------------
    # Public control
    # -----------------------
    def stop(self) -> None:
        """Signal the worker to stop (graceful)."""
        _LOGGER.info("FirebaseWorker stop requested")
        self._stop_event.set()

    # -----------------------
    # Run-loop
    # -----------------------
    def run(self) -> None:
        _LOGGER.info("FirebaseWorker starting (max_retries=%s dead_letter=%s)", self.max_retries, self.dead_letter_path)
        while not self._stop_event.is_set():
            try:
                payload = self.db_queue.get(timeout=self.poll_timeout)
            except queue.Empty:
                continue

            # ensure payload is a dict
            if not isinstance(payload, dict):
                _LOGGER.warning("Dropping non-dict payload: %r", payload)
                self.db_queue.task_done()
                continue

            # Support retry metadata embedded in payload to survive restarts if you persist queue externally
            retries = int(payload.pop("_retries", 0))

            success = False
            try:
                success = self._process_once(payload)
            except Exception:
                _LOGGER.exception("Unhandled exception during payload processing: %s", payload)

            if success:
                # done
                self.db_queue.task_done()
                continue

            # failed -> retry logic
            retries += 1
            if retries <= self.max_retries:
                # backoff and re-enqueue
                backoff = self.retry_base_seconds * (2 ** (retries - 1))
                _LOGGER.warning("Payload processing failed; will retry %s/%s after %.1fs: %s", retries, self.max_retries, backoff, payload.get("op"))
                # reattach retries count
                payload["_retries"] = retries
                # Sleep before requeue to avoid tight-loop; here we sleep in worker thread,
                # which is acceptable since requeue order doesn't need immediate re-insert.
                time.sleep(backoff)
                try:
                    self.db_queue.put_nowait(payload)
                except queue.Full:
                    _LOGGER.warning("DB queue full when trying to requeue; dead-lettering payload: %s", payload.get("op"))
                    self._dead_letter(payload)
                finally:
                    self.db_queue.task_done()
                continue
            else:
                _LOGGER.error("Payload exhausted retries (%s) â€” dead-lettering: %s", self.max_retries, payload.get("op"))
                self._dead_letter(payload)
                self.db_queue.task_done()
                continue

        _LOGGER.info("FirebaseWorker exiting")

    # -----------------------
    # Processing helper
    # -----------------------
    def _process_once(self, payload: Dict[str, Any]) -> bool:
        """
        Attempt a single processing attempt. Returns True on success, False on transient/expected failure.
        If process_fn is None, this method will dead-letter and return True to avoid infinite retries.
        """
        if self.process_fn is None:
            # safe fallback: write payload to dead-letter (so we don't spin) and treat as 'handled'
            _LOGGER.warning("No process_fn available; writing payload to dead-letter: %s", payload.get("op"))
            self._dead_letter(payload)
            return True

        try:
            result = bool(self.process_fn(payload))
            if result:
                _LOGGER.debug("Processed payload op=%s successfully", payload.get("op"))
            else:
                _LOGGER.debug("process_fn returned False (transient failure) for op=%s", payload.get("op"))
            return result
        except Exception:
            _LOGGER.exception("process_fn raised exception for payload op=%s: %s", payload.get("op"), traceback.format_exc())
            return False

    # -----------------------
    # Dead-letter persistence
    # -----------------------
    def _dead_letter(self, payload: Dict[str, Any]) -> None:
        """
        Append the failing payload as newline-delimited JSON to dead_letter_path for offline inspection/replay.
        Include timestamp and optional traceback.
        """
        try:
            rec = {
                "ts": time.time(),
                "payload": payload,
            }
            with open(self.dead_letter_path, "a", encoding="utf-8") as fh:
                fh.write(json.dumps(rec, default=str) + "\n")
            _LOGGER.info("Dead-lettered payload op=%s to %s", payload.get("op"), self.dead_letter_path)
        except Exception:
            _LOGGER.exception("Failed to write dead-letter for payload: %s", payload.get("op"))


# -----------------------
# Convenience helper: example process_fn that tries to dispatch to db.firebase_helpers
# -----------------------
def example_process_fn(payload: Dict[str, Any]) -> bool:
    """
    Example concrete dispatcher. Attempts to import db.firebase_helpers and call a process_payload()
    function if available; otherwise returns False to indicate failure.

    If you have a concrete firebase_helpers.process_payload(payload) function, you can use it directly.
    """
    try:
        import db.firebase_helpers as fh  # type: ignore
        if hasattr(fh, "process_payload"):
            return bool(getattr(fh, "process_payload")(payload))
        # Fallback: try mapping "op" keys to named functions (best-effort)
        op = payload.get("op")
        if op == "session_start" and hasattr(fh, "create_session"):
            return bool(fh.create_session(payload.get("session")))
        if op == "session_end" and hasattr(fh, "update_session_end"):
            return bool(fh.update_session_end(payload.get("session")))
        # extend this mapper to match your firebase_helpers API
        _LOGGER.warning("No matching handler for op=%s in firebase_helpers", op)
        return False
    except Exception:
        _LOGGER.exception("example_process_fn failed while dispatching payload: %s", payload.get("op"))
        return False
